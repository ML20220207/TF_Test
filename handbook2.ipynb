{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handbook2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMm1I6ljv4XWDP0qWp70zoW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ML20220207/TF_Test/blob/main/handbook2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DKtbn0euPPXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save ML models\n",
        "\n",
        "\n",
        "```\n",
        "model.save('my_model.h5')\n",
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()\n",
        "```\n",
        "https://www.tensorflow.org/tutorials/keras/save_and_load\n"
      ],
      "metadata": {
        "id": "5bmnfb4XSMUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and train models for binary classification.\n",
        "\n",
        "\n",
        "```\n",
        "model_7 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 1, ReLU activation\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, ReLU activation\n",
        "  tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) # ouput layer, sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history = model_7.fit(X, y, epochs=100, verbose=0)\n",
        "\n",
        "# Evaluate our model\n",
        "model_7.evaluate(X, y)\n",
        "```\n",
        "https://github.com/ML20220207/TFbasics/blob/main/03_neural_network_classification.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "wEMRicCzSdrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and train models for multi-class categorization.\n",
        "\n",
        "If you want to provide labels as integers, please use SparseCategoricalCrossentropy loss\n",
        "\n",
        "[about loss function](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy)\n",
        "\n",
        "```\n",
        "# Create the model\n",
        "model_12 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer (we had to reshape 28x28 to 784)\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\") # output shape is 10, activation is softmax\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_12.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model (to the normalized data)\n",
        "norm_history = model_12.fit(train_data,\n",
        "                            train_labels,\n",
        "                            epochs=10,\n",
        "                            validation_data=(test_data, test_labels))\n",
        "```\n",
        "\n",
        "https://github.com/ML20220207/TFbasics/blob/main/03_neural_network_classification.ipynb"
      ],
      "metadata": {
        "id": "qdyDufa8Uab1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot loss and accuracy of a trained model.\n",
        "1.pd.DataFrame(history.history).plot(title=\"model_12\");\n",
        "\n",
        "2.\n",
        "\n",
        "```\n",
        "from matplotlib import pyplot as plt\n",
        "def plot_loss_acc(history):\n",
        "  '''Plots the training and validation loss and accuracy from a history object'''\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ZG6eJaaRVk_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify strategies to prevent overfitting, including augmentation and dropout.\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "\n",
        "https://github.com/ML20220207/TF_Test/blob/main/02_CNN_.ipynb"
      ],
      "metadata": {
        "id": "A5sx2ErjXdiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use pretrained models (transfer learning).\n",
        "first look at \n",
        "\n",
        "https://github.com/ML20220207/TF_Test/blob/main/assignment/C2W3_Assignment.ipynb\n",
        "\n",
        "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C2/W3/ungraded_lab/C2_W3_Lab_1_transfer_learning.ipynb\n",
        "\n",
        "https://github.com/ML20220207/TF_Test/blob/main/02_CNN_.ipynb\n",
        "\n",
        "details:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "                                              \n",
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)                                            \n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "base_model.trainable = True\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "jym44vXpago_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensure that inputs to a model are in the correct shape.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Add an extra dimension (to the end)\n",
        "rank_3_tensor = rank_2_tensor[..., tf.newaxis]\n",
        "\n",
        "tf.expand_dims(rank_2_tensor, axis=-1) # \"-1\" means last axis\n",
        "\n",
        "# Squeeze tensor G (remove all 1 dimensions)\n",
        "G_squeezed = tf.squeeze(G)\n",
        "\n",
        "np.reshape(a, (3,-1))  \n",
        "\n",
        "np.expand_dims(x, axis=0)\n",
        "np.expand_dims(x, axis=-1)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ApDvTphGcxwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use callbacks to trigger the end of training cycles.\n",
        "\n",
        "https://github.com/ML20220207/TF_Test/blob/main/01_easy_examples_from_DeepLearning_AI_course.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "32rAvXRYpc_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use datasets in different formats, including json and csv.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "with open(\"./sarcasm.json\", 'r') as f:\n",
        "    datastore = json.load(f)\n",
        "\n",
        "\n",
        "sentences = [] \n",
        "labels = []\n",
        "urls = []\n",
        "for item in datastore:\n",
        "    sentences.append(item['headline'])\n",
        "    labels.append(item['is_sarcastic'])\n",
        "    urls.append(item['article_link'])\n",
        "```\n",
        "https://github.com/ML20220207/TF_Test/blob/main/03_1_NLP.ipynb\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "sentences = []\n",
        "labels = []\n",
        "with open(\"./bbc-text.csv\", 'r') as csvfile:\n",
        "    ### START CODE HERE\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        labels.append(row[0])\n",
        "        sentence = row[1]\n",
        "        for word in stopwords:\n",
        "            token = \" \" + word + \" \"\n",
        "            sentence = sentence.replace(token, \" \")\n",
        "            sentence = sentence.replace(\"  \", \" \")\n",
        "        sentences.append(sentence)\n",
        "    ### END CODE HERE\n",
        "```\n",
        "\n",
        "https://github.com/ML20220207/TF_Test/blob/main/assignment/C3_W1_Assignment.ipynb\n"
      ],
      "metadata": {
        "id": "n8y_OqiQqDt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use datasets from tf.data.datasets."
      ],
      "metadata": {
        "id": "yCsmc31GrVWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/ML20220207/TF_Test/blob/main/01_easy_examples_from_DeepLearning_AI_course.ipynb\n",
        "\n",
        "```\n",
        "# Load the Fashion MNIST dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# Load the training and test split of the Fashion MNIST dataset\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dd-6szg0ct8Z"
      }
    }
  ]
}